{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f723d4db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü¶• Unsloth: Will patch your computer to enable 2x faster free finetuning.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'torch._inductor' has no attribute 'config'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01munsloth\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m FastLanguageModel\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtrl\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SFTTrainer\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/mouse-learning/cl-rl-course-work/.venv/lib/python3.12/site-packages/unsloth/__init__.py:95\u001b[39m\n\u001b[32m     83\u001b[39m         \u001b[38;5;28mprint\u001b[39m(\n\u001b[32m     84\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mUnsloth: Please update Unsloth and Unsloth-Zoo to the latest version!\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m     85\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mDo this via `pip install --upgrade --force-reinstall --no-cache-dir --no-deps unsloth unsloth_zoo`\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     86\u001b[39m         )\n\u001b[32m     87\u001b[39m         \u001b[38;5;66;03m# if os.environ.get(\"UNSLOTH_DISABLE_AUTO_UPDATES\", \"0\") == \"0\":\u001b[39;00m\n\u001b[32m     88\u001b[39m         \u001b[38;5;66;03m#     try:\u001b[39;00m\n\u001b[32m     89\u001b[39m         \u001b[38;5;66;03m#         os.system(\"pip install --upgrade --no-cache-dir --no-deps unsloth_zoo\")\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     93\u001b[39m         \u001b[38;5;66;03m#         except:\u001b[39;00m\n\u001b[32m     94\u001b[39m         \u001b[38;5;66;03m#             raise ImportError(\"Unsloth: Please update unsloth_zoo via `pip install --upgrade --no-cache-dir --no-deps unsloth_zoo`\")\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m95\u001b[39m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01munsloth_zoo\u001b[39;00m\n\u001b[32m     96\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m PackageNotFoundError:\n\u001b[32m     97\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[32m     98\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mUnsloth: Please install unsloth_zoo via `pip install unsloth_zoo` then retry!\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     99\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/mouse-learning/cl-rl-course-work/.venv/lib/python3.12/site-packages/unsloth_zoo/__init__.py:194\u001b[39m\n\u001b[32m    191\u001b[39m \u001b[38;5;66;03m# Log Unsloth-Zoo Utilities\u001b[39;00m\n\u001b[32m    192\u001b[39m os.environ[\u001b[33m\"\u001b[39m\u001b[33mUNSLOTH_ZOO_IS_PRESENT\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[33m\"\u001b[39m\u001b[33m1\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m194\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtemporary_patches\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m    195\u001b[39m     encode_conversations_with_harmony,\n\u001b[32m    196\u001b[39m )\n\u001b[32m    197\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mrl_environments\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m    198\u001b[39m     check_python_modules,\n\u001b[32m    199\u001b[39m     create_locked_down_function,\n\u001b[32m   (...)\u001b[39m\u001b[32m    203\u001b[39m     launch_openenv,\n\u001b[32m    204\u001b[39m )\n\u001b[32m    206\u001b[39m \u001b[38;5;66;03m# Top some pydantic warnings\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/mouse-learning/cl-rl-course-work/.venv/lib/python3.12/site-packages/unsloth_zoo/temporary_patches/__init__.py:18\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Unsloth Zoo - Utilities for Unsloth\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# Copyright 2023-present Daniel Han-Chen, Michael Han-Chen & the Unsloth team. All rights reserved.\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     14\u001b[39m \u001b[38;5;66;03m# You should have received a copy of the GNU Lesser General Public License\u001b[39;00m\n\u001b[32m     15\u001b[39m \u001b[38;5;66;03m# along with this program.  If not, see <https://www.gnu.org/licenses/>.\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcommon\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m *\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mgemma\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m *\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmisc\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m *\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/mouse-learning/cl-rl-course-work/.venv/lib/python3.12/site-packages/unsloth_zoo/temporary_patches/common.py:39\u001b[39m\n\u001b[32m     37\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01minspect\u001b[39;00m\n\u001b[32m     38\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m39\u001b[39m inductor_config_source = inspect.getsource(\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_inductor\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconfig\u001b[49m)\n\u001b[32m     41\u001b[39m \u001b[38;5;129m@functools\u001b[39m.lru_cache(\u001b[32m1\u001b[39m)\n\u001b[32m     42\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdetermine_compile_threads\u001b[39m():\n\u001b[32m     43\u001b[39m     \u001b[38;5;66;03m# See https://github.com/pytorch/pytorch/blob/ab2294d8289a7757a2fc321cdefac88e2b378edf/torch/_inductor/config.py#L771\u001b[39;00m\n\u001b[32m     44\u001b[39m     \u001b[38;5;66;03m# Windows thread count = 1. See https://github.com/unslothai/unsloth-zoo/pull/187\u001b[39;00m\n\u001b[32m     45\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m sys.platform == \u001b[33m\"\u001b[39m\u001b[33mwin32\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[32m1\u001b[39m\n",
      "\u001b[31mAttributeError\u001b[39m: module 'torch._inductor' has no attribute 'config'"
     ]
    }
   ],
   "source": [
    "from unsloth import FastLanguageModel\n",
    "import torch\n",
    "from trl import SFTTrainer\n",
    "from transformers import TrainingArguments\n",
    "from datasets import load_dataset\n",
    "from vllm import LLM, SamplingParams\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aadec636",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASETS_DIR = \"./datasets\"\n",
    "os.makedirs(DATASETS_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b4fb62",
   "metadata": {},
   "outputs": [],
   "source": [
    "mbpp = load_dataset(\"google-research-datasets/mbpp\", \"sanitized\", cache_dir=DATASETS_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61bc8851",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"models\", exist_ok=True)\n",
    "\n",
    "# MODEL_NAME = \"Qwen/Qwen3-0.6B\"\n",
    "MODEL_NAME = \"Qwen/Qwen3-4B-Instruct-2507\"\n",
    "# MODEL_PATH = \"models/qwen3-0.6b\"\n",
    "MODEL_PATH = \"models/qwen3-4B-instruct-2507\"\n",
    "# OUTPUT_MODEL_DIR = \"models/qwen3-0.6b-sft\"\n",
    "OUTPUT_MODEL_DIR = MODEL_PATH + \"-sft\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f855bb47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth 2026.1.3: Fast Qwen3 patching. Transformers: 4.57.3. vLLM: 0.13.0.\n",
      "   \\\\   /|    NVIDIA GeForce RTX 4070 Ti SUPER. Num GPUs = 1. Max memory: 15.992 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.9.0+cu128. CUDA: 8.9. CUDA Toolkit: 12.8. Triton: 3.5.0\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.33.post1. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64378156b43b4470af17d88f15509157",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "\tmodel_name = MODEL_PATH,\n",
    "\tmax_seq_length=2048,\n",
    "\tdtype=None,\n",
    "\tload_in_4bit = True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27bdafaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth 2026.1.3 patched 36 layers with 36 QKV layers, 36 O layers and 36 MLP layers.\n"
     ]
    }
   ],
   "source": [
    "# 2. –ù–∞–≤–µ—à–∏–≤–∞–µ–º –∞–¥–∞–ø—Ç–µ—Ä—ã LoRA\n",
    "model = FastLanguageModel.get_peft_model(\n",
    "    model,\n",
    "    r = 64,\n",
    "    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
    "                      \"gate_proj\", \"up_proj\", \"down_proj\"],\n",
    "    lora_alpha = 64,\n",
    "    lora_dropout = 0,\n",
    "    bias = \"none\",\n",
    "    use_gradient_checkpointing = \"unsloth\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0febbbdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_signature_from_mbpp_code(code: str) -> str:\n",
    "    # –ë–µ—Ä—ë–º –ø–µ—Ä–≤—É—é —Å—Ç—Ä–æ–∫—É, –Ω–∞—á–∏–Ω–∞—é—â—É—é—Å—è —Å def ...\n",
    "    for line in code.splitlines():\n",
    "        line = line.strip()\n",
    "        if line.startswith(\"def \"):\n",
    "            return line.rstrip(\":\")  # –º–æ–∂–Ω–æ –æ—Å—Ç–∞–≤–∏—Ç—å –∏–ª–∏ —É–±—Ä–∞—Ç—å :\n",
    "    raise ValueError(\"No function signature found\")\n",
    "\n",
    "\n",
    "def build_mbpp_prompt(example: dict) -> dict:\n",
    "    # –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–æ: -> dict, —Ç–∞–∫ –∫–∞–∫ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º —Å–ª–æ–≤–∞—Ä—å\n",
    "    task_text = example[\"prompt\"]\n",
    "    code_solution = example[\"code\"]\n",
    "\n",
    "    # –ü—Ä–µ–¥–ø–æ–ª–æ–∂—É, —á—Ç–æ —ç—Ç–∞ —Ñ—É–Ω–∫—Ü–∏—è –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–∞ –∏–ª–∏ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∞ –≥–¥–µ-—Ç–æ —Ä—è–¥–æ–º\n",
    "    signature_line = extract_signature_from_mbpp_code(example[\"code\"])\n",
    "\n",
    "    system_msg = (\n",
    "        \"You are an expert Python coding assistant. \"\n",
    "        \"Given a problem description and function signature, \"\n",
    "        \"implement the function body so that it passes all tests.\"\n",
    "    )\n",
    "\n",
    "    user_msg = (\n",
    "        \"Problem:\\n\"\n",
    "        f\"{task_text}\\n\\n\"\n",
    "        \"Use the following function signature:\\n\"\n",
    "        f\"{signature_line}:\\n\\n\"\n",
    "        \"Write the full Python function implementation. \"\n",
    "        \"Do NOT change the function name or arguments. \"\n",
    "        \"Return only Python code.\"\n",
    "    )\n",
    "\n",
    "    assistant_msg = (\n",
    "        f\"```python\\n{code_solution}\\n```\"\n",
    "    )\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_msg},\n",
    "        {\"role\": \"user\", \"content\": user_msg},\n",
    "        {\"role\": \"assistant\", \"content\": assistant_msg},\n",
    "    ]\n",
    "\n",
    "    prompt = tokenizer.apply_chat_template(\n",
    "        messages,\n",
    "        tokenize=False,\n",
    "        add_generation_prompt=False,\n",
    "    )\n",
    "\n",
    "    return {\"text\": prompt}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef1802f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['source_file', 'task_id', 'prompt', 'code', 'test_imports', 'test_list', 'text'],\n",
       "        num_rows: 120\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['source_file', 'task_id', 'prompt', 'code', 'test_imports', 'test_list', 'text'],\n",
       "        num_rows: 257\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['source_file', 'task_id', 'prompt', 'code', 'test_imports', 'test_list', 'text'],\n",
       "        num_rows: 43\n",
       "    })\n",
       "    prompt: Dataset({\n",
       "        features: ['source_file', 'task_id', 'prompt', 'code', 'test_imports', 'test_list', 'text'],\n",
       "        num_rows: 7\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = mbpp.map(build_mbpp_prompt)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de0dca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. –¢—Ä–µ–Ω–µ—Ä\n",
    "trainer = SFTTrainer(\n",
    "    model = model,\n",
    "    tokenizer = tokenizer,\n",
    "    train_dataset = dataset[\"train\"],\n",
    "    dataset_text_field = \"text\",\n",
    "    max_seq_length = 2048,\n",
    "    packing = False,\n",
    "    args = TrainingArguments(\n",
    "        per_device_train_batch_size = 4,\n",
    "        gradient_accumulation_steps = 4,\n",
    "        max_steps = 100, # –û–±—É—á–∞–µ–º –Ω–µ–º–Ω–æ–≥–æ –¥–ª—è —Ç–µ—Å—Ç–∞\n",
    "        learning_rate = 2e-4,\n",
    "        fp16 = not torch.cuda.is_bf16_supported(),\n",
    "        bf16 = torch.cuda.is_bf16_supported(),\n",
    "        logging_steps = 10,\n",
    "        output_dir = \"checkpoints\",\n",
    "        optim = \"adamw_8bit\",\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d2fcc58",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The model is already on multiple devices. Skipping the move to device specified in `args`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–ù–∞—á–∏–Ω–∞–µ–º –æ–±—É—á–µ–Ω–∏–µ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
      "   \\\\   /|    Num examples = 120 | Num Epochs = 13 | Total steps = 100\n",
      "O^O/ \\_/ \\    Batch size per device = 4 | Gradient accumulation steps = 4\n",
      "\\        /    Data Parallel GPUs = 1 | Total batch size (4 x 4 x 1) = 16\n",
      " \"-____-\"     Trainable parameters = 132,120,576 of 4,154,588,672 (3.18% trained)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='100' max='100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [100/100 02:02, Epoch 12/13]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.165000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.397000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.296000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.174200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.095400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.063200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.045500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.040200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.035400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.034300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–°–æ—Ö—Ä–∞–Ω—è–µ–º –æ–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—É—é –º–æ–¥–µ–ª—å –≤ models/qwen3-4B-instruct-2507-sft...\n",
      "Detected local model directory: /home/pavel/projects/mouse-learning/cl-rl-course-work/models/qwen3-4B-instruct-2507\n",
      "Found HuggingFace hub cache directory: /home/pavel/.cache/huggingface/hub\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth: Preparing safetensor model files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:00<00:00, 12098.95it/s]\n",
      "Unsloth: Merging weights into 16bit: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:34<00:00, 11.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: Merge process complete. Saved to `/home/pavel/projects/mouse-learning/cl-rl-course-work/models/qwen3-4B-instruct-2507-sft`\n",
      "–ì–æ—Ç–æ–≤–æ! –¢–µ–ø–µ—Ä—å –∑–∞–ø—É—Å–∫–∞–π —Å–≤–æ–π —Å–∫—Ä–∏–ø—Ç –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"–ù–∞—á–∏–Ω–∞–µ–º –æ–±—É—á–µ–Ω–∏–µ...\")\n",
    "trainer.train()\n",
    "\n",
    "# 5. –°–û–•–†–ê–ù–ï–ù–ò–ï (–°–∞–º–æ–µ –≤–∞–∂–Ω–æ–µ –¥–ª—è —Ç–≤–æ–µ–≥–æ —Å–∫—Ä–∏–ø—Ç–∞)\n",
    "# –ú—ã —Å–ª–∏–≤–∞–µ–º –≤–µ—Å–∞ (Merge) –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ–º –≤ —Ñ–æ—Ä–º–∞—Ç–µ, –ø–æ–Ω—è—Ç–Ω–æ–º vLLM\n",
    "print(f\"–°–æ—Ö—Ä–∞–Ω—è–µ–º –æ–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—É—é –º–æ–¥–µ–ª—å –≤ {OUTPUT_MODEL_DIR}...\")\n",
    "model.save_pretrained_merged(OUTPUT_MODEL_DIR, tokenizer, save_method=\"merged_16bit\")\n",
    "tokenizer.save_pretrained(OUTPUT_MODEL_DIR)\n",
    "print(\"–ì–æ—Ç–æ–≤–æ! –¢–µ–ø–µ—Ä—å –∑–∞–ø—É—Å–∫–∞–π —Å–≤–æ–π —Å–∫—Ä–∏–ø—Ç –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c02bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_mbpp_prompt_test(example: dict) -> dict:\n",
    "    task_text = example[\"prompt\"]\n",
    "    # –ü—Ä–µ–¥–ø–æ–ª–æ–∂—É, —á—Ç–æ —ç—Ç–∞ —Ñ—É–Ω–∫—Ü–∏—è –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–∞ –∏–ª–∏ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∞ –≥–¥–µ-—Ç–æ —Ä—è–¥–æ–º\n",
    "    signature_line = extract_signature_from_mbpp_code(example[\"code\"])\n",
    "\n",
    "    system_msg = (\n",
    "        \"You are an expert Python coding assistant. \"\n",
    "        \"Given a problem description and function signature, \"\n",
    "        \"implement the function body so that it passes all tests.\"\n",
    "    )\n",
    "\n",
    "    user_msg = (\n",
    "        \"Problem:\\n\"\n",
    "        f\"{task_text}\\n\\n\"\n",
    "        \"Use the following function signature:\\n\"\n",
    "        f\"{signature_line}:\\n\\n\"\n",
    "        \"Write the full Python function implementation. \"\n",
    "        \"Do NOT change the function name or arguments. \"\n",
    "        \"Return only Python code.\"\n",
    "    )\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_msg},\n",
    "        {\"role\": \"user\", \"content\": user_msg},\n",
    "    ]\n",
    "\n",
    "    prompt = tokenizer.apply_chat_template(\n",
    "        messages,\n",
    "        tokenize=False,\n",
    "        add_generation_prompt=True,\n",
    "    )\n",
    "\n",
    "    return {\"text\": prompt}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea1304df",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mbpp' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m dataset_test = \u001b[43mmbpp\u001b[49m[\u001b[33m\"\u001b[39m\u001b[33mtest\u001b[39m\u001b[33m\"\u001b[39m].map(build_mbpp_prompt_test)\n\u001b[32m      2\u001b[39m dataset_test[\u001b[32m0\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mtext\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[31mNameError\u001b[39m: name 'mbpp' is not defined"
     ]
    }
   ],
   "source": [
    "dataset_test = mbpp[\"test\"].map(build_mbpp_prompt_test)\n",
    "dataset_test[0][\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a33bcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```python\n",
      "def sort_matrix(M): \n",
      "    result = [j for i in M for j in i]\n",
      "    result.sort()\n",
      "    result = [result[i:i+len(M[0])] for i in range(0, len(result), len(M[0]))]\n",
      "    return result\n",
      "```<|im_end|>\n"
     ]
    }
   ],
   "source": [
    "model_inputs = tokenizer([dataset_test[0][\"text\"]], return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "generated_ids = model.generate(\n",
    "    **model_inputs,\n",
    "    max_new_tokens=250\n",
    ")\n",
    "\n",
    "output_ids = generated_ids[0][len(model_inputs.input_ids[0]):].tolist()\n",
    "print(tokenizer.decode(output_ids).strip(\"\\n\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
