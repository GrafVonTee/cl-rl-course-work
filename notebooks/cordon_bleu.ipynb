{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "22f62aeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skipping import of cpp extensions due to incompatible torch version 2.9.0+cu128 for torchao version 0.14.0         Please see GitHub issue #2919 for more info\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import functools\n",
    "from tqdm.auto import tqdm\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
    "from peft import PeftModel\n",
    "\n",
    "# –ù–∞—à–∏ –Ω–æ–≤—ã–µ –º–æ–¥—É–ª–∏\n",
    "import src.config as config\n",
    "from src.train.ptuning_train import train\n",
    "from src.prompt import mbpp, humaneval\n",
    "from src.data.loader import load_benchmark\n",
    "from src.executor import LocalExecutor\n",
    "from src.metrics import GreedyPass, PassAtk, PercentPassed, MeanEntropy, ExecutionResult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "24bb0849",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8e2d2b8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ùÑÔ∏è –†–µ–∂–∏–º –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞: –ó–∞–≥—Ä—É–∂–∞–µ–º –±–∞–∑—É + P-Tuning –∞–¥–∞–ø—Ç–µ—Ä...\n",
      "üîó –ü–æ–¥–∫–ª—é—á–∞–µ–º –∞–¥–∞–ø—Ç–µ—Ä –∏–∑: ./models/qwen3-0.6b-ptuning\n",
      "‚úÖ –ú–æ–¥–µ–ª—å –≥–æ—Ç–æ–≤–∞ –∫ —Ç–µ—Å—Ç–∞–º!\n"
     ]
    }
   ],
   "source": [
    "if TRAIN:\n",
    "    print(\"üî• –†–µ–∂–∏–º –æ–±—É—á–µ–Ω–∏—è: –ó–∞–ø—É—Å–∫–∞–µ–º train()...\")\n",
    "    model, tokenizer = train()\n",
    "\n",
    "else:\n",
    "    print(f\"‚ùÑÔ∏è –†–µ–∂–∏–º –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞: –ó–∞–≥—Ä—É–∂–∞–µ–º –±–∞–∑—É + P-Tuning –∞–¥–∞–ø—Ç–µ—Ä...\")\n",
    "    bnb_config = BitsAndBytesConfig(\n",
    "        load_in_4bit=True,\n",
    "        bnb_4bit_use_double_quant=True,\n",
    "        bnb_4bit_quant_type=\"nf4\",\n",
    "        bnb_4bit_compute_dtype=torch.float16\n",
    "    )\n",
    "\n",
    "    base_model = AutoModelForCausalLM.from_pretrained(\n",
    "        config.MODEL_PATH,\n",
    "        quantization_config=bnb_config,\n",
    "        device_map=\"auto\",\n",
    "        trust_remote_code=True,\n",
    "        attn_implementation=\"sdpa\"\n",
    "    )\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(config.MODEL_PATH, trust_remote_code=True)\n",
    "\n",
    "    print(f\"üîó –ü–æ–¥–∫–ª—é—á–∞–µ–º –∞–¥–∞–ø—Ç–µ—Ä –∏–∑: {config.PTUNING_MODEL_PATH}\")\n",
    "    model = PeftModel.from_pretrained(base_model, config.PTUNING_MODEL_PATH)\n",
    "\n",
    "\n",
    "model.eval()\n",
    "print(\"‚úÖ –ú–æ–¥–µ–ª—å –≥–æ—Ç–æ–≤–∞ –∫ —Ç–µ—Å—Ç–∞–º!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7f3f1205",
   "metadata": {},
   "outputs": [],
   "source": [
    "# –í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è —ç–Ω—Ç—Ä–æ–ø–∏–∏ (–Ω—É–∂–Ω–∞ –¥–ª—è evaluate_transformers)\n",
    "def calculate_entropy_hf(scores):\n",
    "    \"\"\"–°—á–∏—Ç–∞–µ—Ç —ç–Ω—Ç—Ä–æ–ø–∏—é –ø–æ –ª–æ–≥–∏—Ç–∞–º HuggingFace (Tuple of tensors)\"\"\"\n",
    "    if not scores: return 0.0\n",
    "\n",
    "    entropies = []\n",
    "\n",
    "    for step_logits in scores:\n",
    "        # step_logits: [batch_size, vocab_size]\n",
    "        # –ü–µ—Ä–µ–≤–æ–¥–∏–º –≤ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏\n",
    "        probs = torch.softmax(step_logits, dim=-1)\n",
    "        log_probs = torch.log_softmax(step_logits, dim=-1)\n",
    "\n",
    "        # H = - sum(p * log p) –ø–æ –ø–æ—Å–ª–µ–¥–Ω–µ–π —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏ (vocab)\n",
    "        # –ü–æ–ª—É—á–∞–µ–º [batch_size] —ç–Ω—Ç—Ä–æ–ø–∏–π –¥–ª—è —ç—Ç–æ–≥–æ —à–∞–≥–∞\n",
    "        step_entropy = -(probs * log_probs).sum(dim=-1)\n",
    "\n",
    "        entropies.append(step_entropy) # List of tensors\n",
    "\n",
    "    # –°–æ–±–∏—Ä–∞–µ–º –≤ [steps, batch_size] -> [batch_size, steps]\n",
    "    if not entropies: return [0.0]\n",
    "\n",
    "    # Stack -> [seq_len, batch_size]\n",
    "    entropies_tensor = torch.stack(entropies)\n",
    "\n",
    "    # –°—Ä–µ–¥–Ω–µ–µ –ø–æ –¥–ª–∏–Ω–µ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ -> [batch_size]\n",
    "    mean_entropies = entropies_tensor.mean(dim=0)\n",
    "\n",
    "    return mean_entropies.tolist()\n",
    "\n",
    "def evaluate_transformers(model, tokenizer, tasks, metrics_suite, batch_size=4): # <--- –°–ù–ò–ó–ò–õ –ë–ê–¢–ß –î–û 4\n",
    "    executor = LocalExecutor()\n",
    "    final_results = {}\n",
    "\n",
    "    tokenizer.padding_side = \"left\"\n",
    "    if tokenizer.pad_token is None:\n",
    "        tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "    # –ß–∏—Å—Ç–∏–º –∫–æ–Ω—Ñ–∏–≥\n",
    "    base_config = config.SAMPLING_SETTINGS.copy()\n",
    "    for key in [\"n\", \"temperature\", \"ignore_eos\", \"detokenize\", \"logprobs\", \"stop\"]:\n",
    "        base_config.pop(key, None)\n",
    "    if \"max_tokens\" in base_config:\n",
    "        base_config[\"max_new_tokens\"] = base_config.pop(\"max_tokens\")\n",
    "\n",
    "    grouped = {}\n",
    "    for m in metrics_suite:\n",
    "        cfg_key = str(m.gen_config)\n",
    "        if cfg_key not in grouped: grouped[cfg_key] = []\n",
    "        grouped[cfg_key].append(m)\n",
    "\n",
    "    for cfg_key, metrics in grouped.items():\n",
    "        metric_specific_config = metrics[0].gen_config\n",
    "        generation_kwargs = {**base_config, **metric_specific_config}\n",
    "\n",
    "        if not generation_kwargs.get(\"do_sample\", False):\n",
    "            for k in [\"temperature\", \"top_p\", \"top_k\"]:\n",
    "                generation_kwargs.pop(k, None)\n",
    "\n",
    "        print(f\"\\nüöÄ Generation for: {[m.name for m in metrics]} | Batch Size: {batch_size}\")\n",
    "\n",
    "        all_exec_results = []\n",
    "\n",
    "        # tqdm —Å –æ—á–∏—Å—Ç–∫–æ–π\n",
    "        pbar = tqdm(range(0, len(tasks), batch_size), desc=\"Eval Batches\")\n",
    "\n",
    "        for i in pbar:\n",
    "            try:\n",
    "                batch_tasks = tasks[i : i + batch_size]\n",
    "                batch_prompts = [t.prompt for t in batch_tasks]\n",
    "\n",
    "                inputs = tokenizer(\n",
    "                    batch_prompts,\n",
    "                    return_tensors=\"pt\",\n",
    "                    padding=True,\n",
    "                    truncation=True\n",
    "                ).to(model.device)\n",
    "\n",
    "                input_len = inputs.input_ids.shape[1]\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    outputs = model.generate(\n",
    "                        **inputs,\n",
    "                        pad_token_id=tokenizer.eos_token_id,\n",
    "                        return_dict_in_generate=True,\n",
    "                        output_scores=True, # –ù—É–∂–Ω–æ –¥–ª—è —ç–Ω—Ç—Ä–æ–ø–∏–∏, –Ω–æ –µ—Å—Ç –ø–∞–º—è—Ç—å\n",
    "                        **generation_kwargs\n",
    "                    )\n",
    "\n",
    "                # –°—á–∏—Ç–∞–µ–º —ç–Ω—Ç—Ä–æ–ø–∏—é –°–†–ê–ó–£, –ø–æ–∫–∞ —Ç–µ–Ω–∑–æ—Ä—ã –≤ –ø–∞–º—è—Ç–∏, —á—Ç–æ–±—ã –ø–æ—Ç–æ–º —É–¥–∞–ª–∏—Ç—å\n",
    "                batch_entropies = [0.0] * len(batch_tasks)\n",
    "                if outputs.scores:\n",
    "                    # scores - —ç—Ç–æ tuple(len=seq_len) of tensors [batch, vocab]\n",
    "                    # –ù–∞—à–∞ —Ñ—É–Ω–∫—Ü–∏—è –≤–µ—Ä–Ω–µ—Ç —Å–ø–∏—Å–æ–∫ [ent_sample_0, ent_sample_1, ...]\n",
    "                    batch_entropies = calculate_entropy_hf(outputs.scores)\n",
    "\n",
    "                # –í–∞–∂–Ω–æ: –æ—Ç–≤—è–∑—ã–≤–∞–µ–º —ç–Ω—Ç—Ä–æ–ø–∏—é –æ—Ç –≥—Ä–∞—Ñ–∞ (—Ö–æ—Ç—è –º—ã –≤ no_grad, –Ω–æ –Ω–∞ –≤—Å—è–∫–∏–π —Å–ª—É—á–∞–π –ø–µ—Ä–µ–≤–æ–¥–∏–º –≤ float)\n",
    "                # calculate_entropy_hf —É–∂–µ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç list[float]\n",
    "\n",
    "                n_samples = generation_kwargs.get(\"num_return_sequences\", 1)\n",
    "\n",
    "                for j, task in enumerate(batch_tasks):\n",
    "                    task_samples = []\n",
    "                    start_idx = j * n_samples\n",
    "                    end_idx = start_idx + n_samples\n",
    "\n",
    "                    # –≠–Ω—Ç—Ä–æ–ø–∏—è –¥–ª—è —Ç–µ–∫—É—â–µ–π –∑–∞–¥–∞—á–∏ (–¥–ª—è greedy n=1, —ç–Ω—Ç—Ä–æ–ø–∏—è –æ–¥–Ω–∞)\n",
    "                    # –ï—Å–ª–∏ n > 1, HF –ø–æ–≤—Ç–æ—Ä—è–µ—Ç –ø—Ä–æ–º–ø—Ç—ã, –Ω–æ outputs.scores —Å–ª–æ–∂–Ω–µ–µ –º–∞–ø–ø—è—Ç—Å—è.\n",
    "                    # –î–ª—è –ø—Ä–æ—Å—Ç–æ—Ç—ã —Å—á–∏—Ç–∞–µ–º, —á—Ç–æ output_scores –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç [batch_size * n_samples, vocab]\n",
    "                    # calculate_entropy_hf –≤–µ—Ä–Ω–µ—Ç —Å–ø–∏—Å–æ–∫ –¥–ª–∏–Ω–æ–π batch_size * n_samples\n",
    "\n",
    "                    for k in range(start_idx, end_idx):\n",
    "                        seq = outputs.sequences[k]\n",
    "                        gen_tokens = seq[input_len:]\n",
    "                        gen_text = tokenizer.decode(gen_tokens, skip_special_tokens=True)\n",
    "\n",
    "                        # –ë–µ—Ä–µ–º —ç–Ω—Ç—Ä–æ–ø–∏—é –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ —Å—ç–º–ø–ª–∞\n",
    "                        sample_entropy = batch_entropies[k] if k < len(batch_entropies) else 0.0\n",
    "\n",
    "                        exec_res = executor.execute(gen_text, task.tests)\n",
    "                        exec_res.entropy = sample_entropy\n",
    "                        task_samples.append(exec_res)\n",
    "\n",
    "                    all_exec_results.append(task_samples)\n",
    "\n",
    "                # === –ê–ì–†–ï–°–°–ò–í–ù–ê–Ø –û–ß–ò–°–¢–ö–ê ===\n",
    "                del inputs\n",
    "                del outputs # –£–¥–∞–ª—è–µ–º 5 –ì–ë –ª–æ–≥–∏—Ç–æ–≤\n",
    "                del batch_entropies\n",
    "                gc.collect()\n",
    "                torch.cuda.empty_cache()\n",
    "                # ===========================\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error in batch {i}: {e}\")\n",
    "                torch.cuda.empty_cache()\n",
    "                continue\n",
    "\n",
    "        for m in metrics:\n",
    "            score = m.calculate(all_exec_results)\n",
    "            final_results[m.name] = score\n",
    "            print(f\"üìä {m.name}: {score:.4f}\")\n",
    "\n",
    "    return final_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b340ec4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì• Loading Datasets...\n",
      "\n",
      "========================================\n",
      "üêç EVALUATING MBPP (Small Subset)\n",
      "========================================\n",
      "\n",
      "üöÄ Generation for: ['greedy@1'] | Batch Size: 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb751350cfca458fbfc7e2bf8f0f4f74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval Batches:   0%|          | 0/65 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "/opt/conda/lib/python3.11/site-packages/peft/peft_model.py:2141: UserWarning: Position ids are not supported for parameter efficient tuning. Ignoring position ids.\n",
      "  warnings.warn(\"Position ids are not supported for parameter efficient tuning. Ignoring position ids.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä greedy@1: 0.2568\n",
      "\n",
      "üöÄ Generation for: ['pass@1 (n=1)', 'mean_%passed', 'mean_entropy'] | Batch Size: 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c65c91f046342828b48b315a23b1e4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval Batches:   0%|          | 0/65 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä pass@1 (n=1): 0.2490\n",
      "üìä mean_%passed: 0.2980\n",
      "üìä mean_entropy: nan\n",
      "\n",
      "========================================\n",
      "üß† EVALUATING HumanEval (Small Subset)\n",
      "========================================\n",
      "\n",
      "üöÄ Generation for: ['greedy@1'] | Batch Size: 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "adce081064a14aea9d7b0ba198758c6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval Batches:   0%|          | 0/41 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.5\n",
      "7.5\n",
      "7.5\n",
      "üìä greedy@1: 0.2195\n",
      "\n",
      "üöÄ Generation for: ['pass@1 (n=1)', 'mean_%passed', 'mean_entropy'] | Batch Size: 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e873b45e6f104f41b3df6cb3b24696d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval Batches:   0%|          | 0/41 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "3\n",
      "2\n",
      "3\n",
      "2\n",
      "3\n",
      "2\n",
      "3\n",
      "2\n",
      "3\n",
      "2\n",
      "3\n",
      "2\n",
      "3\n",
      "2\n",
      "3\n",
      "üìä pass@1 (n=1): 0.2317\n",
      "üìä mean_%passed: 0.3919\n",
      "üìä mean_entropy: nan\n",
      "\n",
      "=== FINAL REPORT ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>greedy@1</th>\n",
       "      <th>pass@1 (n=1)</th>\n",
       "      <th>mean_%passed</th>\n",
       "      <th>mean_entropy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MBPP</th>\n",
       "      <td>0.256809</td>\n",
       "      <td>0.249027</td>\n",
       "      <td>0.297990</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HumanEval</th>\n",
       "      <td>0.219512</td>\n",
       "      <td>0.231707</td>\n",
       "      <td>0.391887</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           greedy@1  pass@1 (n=1)  mean_%passed  mean_entropy\n",
       "MBPP       0.256809      0.249027      0.297990           NaN\n",
       "HumanEval  0.219512      0.231707      0.391887           NaN"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 1. –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö (—á–µ—Ä–µ–∑ –Ω–æ–≤—ã–µ –ª–æ–∞–¥–µ—Ä—ã)\n",
    "print(\"üì• Loading Datasets...\")\n",
    "\n",
    "# –§—É–Ω–∫—Ü–∏—è-–º–∞–ø–ø–µ—Ä —Å \"–∑–∞–ø–µ—á–µ–Ω–Ω—ã–º\" —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä–æ–º\n",
    "mbpp_mapper = functools.partial(mbpp.mbpp_to_task, tokenizer=tokenizer)\n",
    "he_mapper = functools.partial(humaneval.humaneval_to_task, tokenizer=tokenizer)\n",
    "\n",
    "# –ì—Ä—É–∑–∏–º —Å—ã—Ä—ã–µ –¥–∞–Ω–Ω—ã–µ\n",
    "ds_mbpp = mbpp.get_dataset()[\"test\"]\n",
    "ds_mbpp_small = ds_mbpp#.select(range(20))\n",
    "\n",
    "ds_he = humaneval.get_dataset()[\"test\"]\n",
    "ds_he_small = ds_he#.select(range(20))\n",
    "\n",
    "tasks_mbpp = load_benchmark(ds_mbpp_small, mbpp_mapper)\n",
    "tasks_he = load_benchmark(ds_he_small, he_mapper)\n",
    "\n",
    "metrics_suite = [\n",
    "\tGreedyPass(),\n",
    "    PassAtk(k=1, n_samples=1),\n",
    "    # PassAtk(k=5, n_samples=5), # –æ–Ω–æ –ø—Ä–æ—Å—Ç–æ –Ω–µ –∑–∞–ø—É—Å–∫–∞–µ—Ç—Å—è, –ø–∞–º—è—Ç—å —É–º–∏—Ä–∞–µ—Ç\n",
    "\tPercentPassed(),\n",
    "    MeanEntropy(),\n",
    "]\n",
    "\n",
    "# 3. –ó–∞–ø—É—Å–∫!\n",
    "print(\"\\n\" + \"=\"*40)\n",
    "print(\"üêç EVALUATING MBPP (Small Subset)\")\n",
    "print(\"=\"*40)\n",
    "results_mbpp = evaluate_transformers(model, tokenizer, tasks_mbpp, metrics_suite)\n",
    "\n",
    "print(\"\\n\" + \"=\"*40)\n",
    "print(\"üß† EVALUATING HumanEval (Small Subset)\")\n",
    "print(\"=\"*40)\n",
    "results_he = evaluate_transformers(model, tokenizer, tasks_he, metrics_suite)\n",
    "\n",
    "# 4. –ò—Ç–æ–≥–æ–≤—ã–π –≤—ã–≤–æ–¥\n",
    "print(\"\\n=== FINAL REPORT ===\")\n",
    "df = pd.DataFrame([results_mbpp, results_he], index=[\"MBPP\", \"HumanEval\"])\n",
    "display(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
